{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from time import sleep\n",
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary too long, summarizing...\n",
      "summary too long, summarizing...\n",
      "summary too long, summarizing...\n",
      "summary too long, summarizing...\n",
      "summary too long, summarizing...\n",
      "summary too long, summarizing...\n"
     ]
    }
   ],
   "source": [
    "def summar_to_score(summ):\n",
    "    # negative => < 0\n",
    "    # positive => > 0\n",
    "    # neutral  => = 0\n",
    "    if len(summ.split()) > 350:\n",
    "        print('summary too long, summarizing...')\n",
    "        summ = summarizer(summ)[0]['summary_text']\n",
    "    result = pipe(summ)[0]\n",
    "    match result['label']:\n",
    "        case 'positive':\n",
    "            return result['score']\n",
    "        case 'negative':\n",
    "            return -result['score']\n",
    "        case 'neutral':\n",
    "            return 0\n",
    "\n",
    "news = pd.read_csv('data/news.csv')\n",
    "news['score'] = news['summary'].apply(summar_to_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine prices normolized by z-score with sentient score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reading CSV files\n",
    "stocks = pd.read_csv('data/5min.csv')\n",
    "news = pd.read_csv('data/news.csv')\n",
    "\n",
    "# Convert 't' and 'datetime' columns to datetime type\n",
    "stocks['date'] = pd.to_datetime(stocks['t'])\n",
    "news['date'] = pd.to_datetime(news['datetime'])\n",
    "\n",
    "# Initialize 'score' column in stocks with empty lists\n",
    "stocks['score'] = stocks.apply(lambda x: [], axis=1)\n",
    "\n",
    "# Sort dataframes by date for efficient searching\n",
    "stocks.sort_values('date', inplace=True)\n",
    "news.sort_values('date', inplace=True)\n",
    "\n",
    "# Iterate through each row in news to find the closest stock entry\n",
    "for i, news_row in news.iterrows():\n",
    "    news_time = news_row['date']\n",
    "\n",
    "    # Find the closest stock time\n",
    "    closest_stock_time = stocks['date'].iloc[(stocks['date'] - news_time).abs().argsort()[:1]]\n",
    "    closest_index = closest_stock_time.index[0]\n",
    "\n",
    "    # Append the score to the closest stock entry\n",
    "    stocks.at[closest_index, 'score'].append(news_row['score'])\n",
    "\n",
    "# Replace empty lists with zero\n",
    "stocks['score'] = stocks['score'].apply(lambda x: 0 if len(x) == 0 else x)\n",
    "\n",
    "# Save the updated stocks DataFrame to CSV\n",
    "stocks.to_csv('data/5min_score.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034363252645622754"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/5min_score_mean.csv')\n",
    "df['o'].std() * 0.035"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "class StockDataset(Dataset):\n",
    "    def __init__(self, array_data, window):\n",
    "        self.array_data = array_data\n",
    "        self.window = window\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.array_data) - self.window\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(self.array_data[idx:idx+self.window], dtype=torch.float32)\n",
    "        y = torch.tensor(self.array_data[idx+self.window], dtype=torch.float32)\n",
    "        return x,y\n",
    "\n",
    "# Load your data into a DataFrame and then convert to a NumPy array\n",
    "df = pd.read_csv('data/5min_score_mean.csv')\n",
    "array_data = df[['z_o', 'z_c', 'z_v', 'score']].to_numpy()\n",
    "\n",
    "# Create a dataset object\n",
    "window = 25  # Specify your window size\n",
    "dataset = StockDataset(array_data, window)\n",
    "\n",
    "# Create a DataLoader object\n",
    "batch_size = 32\n",
    "\n",
    "# Compute lengths of splits\n",
    "total_len = len(dataset)\n",
    "train_len = int(0.7 * total_len)\n",
    "val_len = int(0.2 * total_len)\n",
    "test_len = total_len - train_len - val_len\n",
    "\n",
    "# Randomly split dataset\n",
    "train_set, val_set, test_set = random_split(dataset, [train_len, val_len, test_len])\n",
    "\n",
    "# Create DataLoader objects for each split\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader   = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(test_set, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN AI FINALLY!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "MPS backend out of memory (MPS allocated: 17.20 GB, other allocations: 407.33 MB, max allowed: 18.13 GB). Tried to allocate 1024.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ed/Developer/Crowley/ai_test/main.ipynb Cell 8\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X11sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m x\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X11sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m#test:\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X11sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m model \u001b[39m=\u001b[39m StockPredictor(input_dim)\u001b[39m.\u001b[39;49mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X11sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m x,y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X11sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device); y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1145\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                     non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1143\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1145\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(convert)\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:797\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    795\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    796\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 797\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    799\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    800\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    801\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    802\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    807\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    808\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:197\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[0;32m--> 197\u001b[0m     ret \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    199\u001b[0m     \u001b[39m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    200\u001b[0m     \u001b[39m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     \u001b[39m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    202\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_flat_weights()\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:820\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    817\u001b[0m \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 820\u001b[0m     param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    821\u001b[0m should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    822\u001b[0m \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1143\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1140\u001b[0m \u001b[39mif\u001b[39;00m convert_to_format \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m t\u001b[39m.\u001b[39mdim() \u001b[39min\u001b[39;00m (\u001b[39m4\u001b[39m, \u001b[39m5\u001b[39m):\n\u001b[1;32m   1141\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mto(device, dtype \u001b[39mif\u001b[39;00m t\u001b[39m.\u001b[39mis_floating_point() \u001b[39mor\u001b[39;00m t\u001b[39m.\u001b[39mis_complex() \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   1142\u001b[0m                 non_blocking, memory_format\u001b[39m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1143\u001b[0m \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39;49mto(device, dtype \u001b[39mif\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_floating_point() \u001b[39mor\u001b[39;49;00m t\u001b[39m.\u001b[39;49mis_complex() \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m, non_blocking)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: MPS backend out of memory (MPS allocated: 17.20 GB, other allocations: 407.33 MB, max allowed: 18.13 GB). Tried to allocate 1024.00 MB on private pool. Use PYTORCH_MPS_HIGH_WATERMARK_RATIO=0.0 to disable upper limit for memory allocations (may cause system failure)."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "if os.name == 'posix':\n",
    "    if os.uname()[0] == 'Linux':\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    elif os.uname()[0] == 'Darwin':\n",
    "        device = torch.device('mps')  # 'mps' is not a recognized device in PyTorch, default to CPU on macOS\n",
    "\n",
    "input_dim = 4  # 'z_o', 'z_c', 'z_v', 'score'\n",
    "output_dim = 2  # 'z_o', 'z_c'\n",
    "class StockPredictor(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(StockPredictor, self).__init__()\n",
    "        self.lstm_step1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.LSTM(4096, 8192, batch_first=True, num_layers=7),\n",
    "        )\n",
    "        self.conv_step2 = nn.Sequential(\n",
    "            nn.Conv2d(1, 128, kernel_size=1),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Conv2d(128, 512, kernel_size=3),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Conv2d(512, 32, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # Expand\n",
    "            nn.Conv2d(32, 2048, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            nn.SELU(),\n",
    "            nn.Conv2d(2048, 4096, kernel_size=3),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "        self.lstm_step3 = nn.LSTM(14, 32, batch_first=True, num_layers=20)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        # LSTM step 1\n",
    "        x, (h,_) = self.lstm_step1(x)\n",
    "        h = h[-1:].permute(1,0,2)\n",
    "        x = torch.concat((x,h), dim=1)\n",
    "\n",
    "        # CONV step 2\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.conv_step2(x)\n",
    "        # x = x.squeeze(2)\n",
    "\n",
    "        # # LSTM step 3\n",
    "        # x, (h,_) = self.lstm_step3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "#test:\n",
    "model = StockPredictor(input_dim).to(device)\n",
    "x,y = next(iter(train_loader))\n",
    "x = x.to(device); y = y.to(device)\n",
    "print(\"x:\",torch.flatten(x, start_dim=1).shape)\n",
    "\n",
    "output = model(x)\n",
    "\n",
    "print(\"y:\", output.shape)\n",
    "total_neurons = 0\n",
    "for name, param in model.named_parameters():\n",
    "    if 'weight' in name:\n",
    "        neurons = param.size(0)  # Number of neurons in the current layer\n",
    "        total_neurons += neurons\n",
    "        print(f\"{name} has {neurons} neurons\")\n",
    "\n",
    "print(f\"Total number of neurons: {total_neurons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 4, got 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/ed/Developer/Crowley/ai_test/main.ipynb Cell 8\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m x,y \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39m(\u001b[39miter\u001b[39m(train_loader))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device); y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m output \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39mprint\u001b[39m(output\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# Initialize model, loss, and optimizer\u001b[39;00m\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/ed/Developer/Crowley/ai_test/main.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm_step1(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/ed/Developer/Crowley/ai_test/main.ipynb#X10sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    218\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:810\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    806\u001b[0m     \u001b[39m# Each batch of the hidden state should match the input sequence that\u001b[39;00m\n\u001b[1;32m    807\u001b[0m     \u001b[39m# the user believes he/she is passing in.\u001b[39;00m\n\u001b[1;32m    808\u001b[0m     hx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpermute_hidden(hx, sorted_indices)\n\u001b[0;32m--> 810\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_forward_args(\u001b[39minput\u001b[39;49m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first)\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:730\u001b[0m, in \u001b[0;36mLSTM.check_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    725\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_forward_args\u001b[39m(\u001b[39mself\u001b[39m,  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m    726\u001b[0m                        \u001b[39minput\u001b[39m: Tensor,\n\u001b[1;32m    727\u001b[0m                        hidden: Tuple[Tensor, Tensor],\n\u001b[1;32m    728\u001b[0m                        batch_sizes: Optional[Tensor],\n\u001b[1;32m    729\u001b[0m                        ):\n\u001b[0;32m--> 730\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcheck_input(\u001b[39minput\u001b[39;49m, batch_sizes)\n\u001b[1;32m    731\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_hidden_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    732\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[0] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m    733\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_hidden_size(hidden[\u001b[39m1\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_expected_cell_size(\u001b[39minput\u001b[39m, batch_sizes),\n\u001b[1;32m    734\u001b[0m                            \u001b[39m'\u001b[39m\u001b[39mExpected hidden[1] size \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Developer/Crowley/ai_test/.venv/lib/python3.11/site-packages/torch/nn/modules/rnn.py:218\u001b[0m, in \u001b[0;36mRNNBase.check_input\u001b[0;34m(self, input, batch_sizes)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    215\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput must have \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m dimensions, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    216\u001b[0m             expected_input_dim, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n\u001b[1;32m    217\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size \u001b[39m!=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m--> 218\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    219\u001b[0m         \u001b[39m'\u001b[39m\u001b[39minput.size(-1) must be equal to input_size. Expected \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    220\u001b[0m             \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minput_size, \u001b[39minput\u001b[39m\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 4, got 256"
     ]
    }
   ],
   "source": [
    "# Initialize model, loss, and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00046)\n",
    "scheduler = StepLR(optimizer, step_size=6, gamma=0.7)  # Reduce lr by a factor of 0.7 every 10 epochs\n",
    "\n",
    "# Function to compute \"accuracy\"\n",
    "def compute_accuracy(pred, target, threshold=0.035):\n",
    "    return (torch.abs(pred - target) < threshold).float().mean() * 100\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "    count = 0\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        total_accuracy += compute_accuracy(output[:][:][:2], y_batch[:][:][:2])\n",
    "        count += 1\n",
    "\n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f'Train Epoch: {epoch}, Loss: {total_loss/count:.4f}, Accuracy: {total_accuracy/count:.2f}%')\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        total_val_accuracy = 0\n",
    "        count = 0\n",
    "        for x_batch, y_batch in val_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            \n",
    "            output = model(x_batch)\n",
    "            val_loss = criterion(output, y_batch)\n",
    "\n",
    "            total_val_loss += val_loss.item()\n",
    "            total_val_accuracy += compute_accuracy(output, y_batch)\n",
    "            count += 1\n",
    "\n",
    "    print(f'Val Epoch: {epoch}, Loss: {total_val_loss/count:.4f}, Accuracy: {total_val_accuracy/count:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
